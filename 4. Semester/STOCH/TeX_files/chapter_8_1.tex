\begin{enumerate}[label=]
	\item \ul{Ziel:} ``Übersetze'' Verteilungen in Funktionen. Insbesondere einfache Faltungsoperation ($\nearrow$ 5.3). %TODO ref!
\end{enumerate}
\begin{definition}
	\proplbl{8_1}
	\begin{enumerate}
		\item $(\O,\F,\P)$ Wahrscheinlichkeitsraum $X: \O \to \R$ Zufallsvariable. Dann heißt
		\begin{align*}
			m_X(u) := \E[e^{uX}] \quad u\in \R\text{, so dass } m_X(u) < \infty
		\end{align*}
		\begriff{momenterzeugende Funktion} von $X$ (mgf = moment generating function)
		\item Ist $\P$ Verteilung auf $\R$, so heißt
		\begin{align*}
			m_{\P}(u) = \int_{\R}e^{uX} \P(\d x) \quad u \in \R\text{, so dass } m_{\P}(u) < \infty
		\end{align*}
		\begriff{momenterzeugende Funktion} von $\P$.
	\end{enumerate}
\end{definition}
\begin{example}
	\proplbl{8_2}
	Sei $X \sim \Gam(\lambda,r)$.
	\begin{align*}
		m_X(u) &= \E[e^{uX}]\\
		&= \int_{0}^{\infty} e^{ux}\lambda e^{-\lambda x}\frac{(\lambda x)^{r-1}}{\Gamma(r)}\d x\\
		&= \frac{\lambda^r}{\Gamma(r)} \int_{0}^{\infty}e^{-(\lambda-u)x}x^{r-1}\d x \quad y= (\lambda-u)x\\
		&= \frac{\lambda^r}{\Gamma(r)}\int_0^{\infty} e^{-y}\frac{y^{r-1}}{(\lambda-u)^{r-1}}\frac{\d y}{(\lambda-u)}\\
		&= \brackets{\frac{\lambda}{\lambda-u}}^r \quad u < \lambda
	\end{align*}
\end{example}
\begin{lemma}
	\proplbl{8_3}
	Ist $X$ $\N_0$-wertig, so gilt für alle $u \in \R$ mit $m_X(u) < \infty$
	\begin{align*}
		m_X(u) = \E[e^{uX}] = \psi_X(e^u)
	\end{align*}
\end{lemma}
\begin{proof}
	Klar, da folgt aus \propref{8_1}.
\end{proof}
\begin{proposition}
	\proplbl{8_4}
	$(\O,\F,\P)$ Wahrscheinlichkeitsraum, $X,Y: \O \to \R$ Zufallsvariablen mit mgfs $m_X,m_Y$. Es gelten:
	\begin{enumerate}
		\item $m_X(0) = 1$
		\item $a,b \in \R$
		\begin{align*}
			m_{aX+b}(u) = e^{bu}m_X(au) \quad \text{ für } u \text{ so dass} m_X(au) < \infty
		\end{align*}
		\item $X \perp Y \implies m_{X+Y}(u) = m_X(u)m_Y(u)$ $\forall u$, so dass $m_X(u), m_Y(u) < \infty$ 
	\end{enumerate}
\end{proposition}
\begin{proof}
	\begin{enumerate}
		\item Klar!
		\item Sei $m_{aX+b}(u) = \E[e^{aXu + bu}] = e^{bu} \E[e^{auX}] = e^{bu}m_X(au)$.
		\item \begin{align*}
			m_{X+Y}(u) &= \E[e^{Xu + Yu}] \overset{X\perp Y}{=} \E[e^{uX}]\E[e^{uY}]\\
			&= m_X(u)m_Y(u)
		\end{align*}
	\end{enumerate}
\end{proof}
Der Bezeichnung ``momenterzeugend'' erklärt sich mit der folgenden Proposition:
\begin{proposition}
	\proplbl{8_5}
	Sei $(\O,\F,\P)$ Wahrscheinlichkeitsraum, $X: \O \to \R$ Zufallsvariable mit momenterzeugender Funktion $m_X$, so dass ein $\epsilon > 0$ existiert mit $m_X(u)<\infty$ auf $[0,\epsilon)$. Dann gilt
	\begin{align*}
		\E[X^n] = \frac{\d^n}{\d u^n} m_X(0) \quad \forall n \in \N
	\end{align*}
\end{proposition}
\begin{proof}
	Für alle $u \in \R$ mit $m_X(u) < \infty$ folgt
	\begin{align*}
		m_X(u) &= \E[e^{uX}] = \E\sqbrackets{\sum_{k=0}^{\infty}\frac{(uX)^k}{k!}}\\
		\overset{\person{Lebesgue}}&{=} \sum_{k=0}^{\infty} \frac{\E[X^k]u^k}{k!}
		\intertext{n-fachen Differenzieren folgt}
		\frac{\d^n}{\d u^n}m_X(0) &= \sum_{k=0}^{\infty}\frac{\E[X^k]}{k!}k(k-1)\cdots(k-n+1)u^{k-n}\\
		\intertext{so dass}
		\frac{\d^n}{\d u^n} m_X(0)&= \frac{\E[X^n]}{n!}n(n-1)\cdots(n-n+1) = \E[X^n].
	\end{align*}
\end{proof}
Die mgf charakterisiert eine Verteilung eindeutig:
\begin{proposition}
	\proplbl{8_6}
	Seien $(\O,\F,\R),(\O',\F',\P')$ Wahrscheinlichkeitsräume, $X: \O \to \R, Y: \O' \to \R$ Zufallsvariablen mit mgfs $m_X,m_Y$. Wenn $m_X(u), m_Y(u)$ in einer Umgebung um Null definiert sind und im Definitionsbereich gilt $m_X(u) = m_Y(u)$, so haben $X \und Y$ die selben Verteilungen ($X \distri Y$, d = distribution) 
\end{proposition}
\begin{proof}
	Sind $X,Y$ $\N_0$-wertig, so folgt dies aus \propref{8_3} und dementsprechenden Resultat für pgfs. Der allgemeine Fall folgt aus dem Resultat zu charakteristischen Funktionen (\propref{8_12}). %TODO add ref, when we are there ...
\end{proof}
\begin{example}[(vgl. \cref{4_3})]
	\proplbl{8_7}
	Seien $X \sim \Gam(\lambda,r),Y\sim \Gam(\lambda,s)$ unabhängig, dann gilt nach \propref{8_2}
	\begin{align*}
		m_X(u) = \brackets{\frac{\lambda}{\lambda-u}}^r \quad u < \lambda \und m_Y(u) = \brackets{\frac{\lambda}{\lambda-u}}^s \quad u <\lambda
		\intertext{und nach \propref{8_4}}
		m_{X+Y}(u) = m_X(u)m_Y(u) = \brackets{\frac{\lambda}{\lambda-u}}^r\brackets{\frac{\lambda}{\lambda-u}}^s = \brackets{\frac{\lambda}{\lambda-u}}^{r+s}
	\end{align*}
	Dies ist die mgf einer $\Gam(\lambda,r+s)$ Verteilung. Nach \propref{8_6} folgt $X+Y \sim \Gam(\lambda, r+s)$.
\end{example}
\begin{*anmerkung}
	\begin{itemize}
		\item pgf: $\psi_X(u) = \E[u^X]$
		\item mgf: $m_X(u) = \E[e^{uX}]$
	\end{itemize}
\end{*anmerkung}
\begin{definition}
	\proplbl{8_8}
	\begin{enumerate}
		\item Sei $(\O,\F,\P)$ Wahrscheinlichkeitsraum, $X: \O \to \Rd$ Zufallsvariable. Dann ist
		\begin{align*}
			\varphi_X(u) := \E[e^{\ii\scaProd{u}{X}}]\quad u \in \Rd
		\end{align*}
		\begriff{charakteristische Funktion von $X$}.
		\item Ist $\P$ Verteilung in $\Rd$, dann ist
		\begin{align*}
			\varphi_{\P}(u) = \int_{\Rd} e^{\ii\scaProd{u}{X}}\P(\d x) \quad u \in \Rd
		\end{align*}
		\begriff{charakteristische Funktion von $\P$}.
	\end{enumerate}
\end{definition}
\begin{*remark}
	\begin{itemize}
		\item Da $\abs{e^{\ii\scaProd{u}{X}}} =1$, ist die charakteristische Funktion für \emph{alle} $u \in \Rd$ definiert.
		\item Die charakteristische Funktion ist die inverse \person{Fourier}transformation des Maßes $\P$ bzw. $\P_X$. Die mgf ist hingegen mit der \person{Laplace}transformation verwandt.
		\item Existiert die mgf in einer Umgebung der Null, dann ist sie dort holomorph (komplex diffbar) und kann daher in die komplexe Ebene fortgesetzt werden (siehe $\nearrow$ Funktionentheorie). Dies führt auf die charakteristische Funktion.
		\item Ist $X$ eine $\N_0$-wertige Funktion, so gilt
		\begin{align*}
			\varphi_X(u) = \psi_X(e^{\ii u})
		\end{align*}
	\end{itemize}
\end{*remark}
\begin{example}
	\proplbl{8_9}
	Sei $X \sim \Gam(\lambda,r)$. Dann folgt mittels Rechnung wie in \propref{8_2} und dem Integralsatz von \person{Cauchy}:
	\begin{align*}
		\varphi_X(u) = \brackets{\frac{\lambda}{\lambda-\ii u}}^r \quad u \in \R
	\end{align*}
\end{example}
\begin{proposition}[Rechenregeln]
	\proplbl{8_10}
	Sei $(\O,\F,\P)$ Wahrscheinlichkeitsraum, $X,Y: \O \to \Rd$ mit charakteristischer Funktion $\varphi_X,\varphi_Y$. Dann
	\begin{enumerate}
		\item $\varphi_X(0) = 1$
		\item Seien $A \in \Rnn, b \in \Rn$. Dann gilt
			\begin{align*}
				\varphi_{AX + b}(u) = e^{\ii \scaProd{u}{b}} \varphi_X(A^T u)
			\end{align*} 
		\item Wenn $X \upmodels Y$ dann folgt $\varphi_{X+Y}(u) = \varphi_X(u)\varphi_Y(u) \quad u \in \Rd$
	\end{enumerate}
\end{proposition}
\begin{proof}
	Analog zu \propref{8_4}.
\end{proof}
\begin{proposition}
	\proplbl{8_11} 
	Sei $X \sim \normal(\mu,\sigma^2)$, dann
	\begin{align*}
		\varphi_X(u) = e^{\ii \mu u - \frac{\sigma^2 u^2}{2}} \quad u \in \R
		\intertext{und insbesondere}
		\varphi_{\normal(0,1)}(u) = e^{-\frac{u^2}{2}} \quad u \in \R
	\end{align*}
\end{proposition}
\begin{proof}
	Betrachte die Standardnormalverteilung:
	\begin{align*}
		\varphi(u) &:= \varphi_{\normal(0,1)}(u) = \int_{\R} e^{\ii u x} \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}\d x
		\intertext{Mit dem Differenzierbarkeitslemma für Parameterintergrale ($\nearrow$ Schilling MINT, Satz 12.2)}
		\varphi'(u) &= \int_{\R} \brackets{\frac{\d}{\d u}e^{\ii ux}}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \d x\\
		&= \frac{1}{\sqrt{2\pi}} \int_{\R} \ii x e^{\ii ux} e^{-\frac{x^2}{2}}\d x\\
		&= \frac{1}{\sqrt{2\pi}} \int_{\R} (-\ii)e^{\ii u x} \brackets{\frac{\d}{\d x} e^{-\frac{x^2}{2}}}\d x\\
		\over{\text{P.I.}}&{=} \underbrace{\frac{-\ii}{\sqrt{2\pi}} \sqbrackets{e^{\ii u x}e^{-\frac{x^2}{2}}}_{x=-\infty}^{\infty}}_{=0} + \frac{1}{\sqrt{2\pi}} \int_{\O} \ii \brackets{\frac{\d}{\d x} e^{\ii ux}}\d x\\
		&= \frac{1}{\sqrt{2\pi}} \int_{\R} \ii \ii u e^{\ii u} e^{-\frac{x^2}{2}}\d x\\
		&= -u \frac{1}{\sqrt{2\pi}} \int_{\R} e^{u x}e^{-\frac{x^2}{2}}\d x\\
		&= - u \varphi(u)	
	\end{align*}
	Die DGL $\varphi'(u) = -u\varphi(u)$ besitzt die Lösung
	\begin{align*}
		\varphi(u) = \varphi(0)e^{-\frac{x^2}{2}}
	\end{align*}
	mit $\varphi(0) =1$ nach \propref{8_10}, also folgt $\varphi(u) = e^{-\frac{u^2}{2}}$. Für $X \sim \normal(\mu, \sigma^2)$ gilt $Z:= \frac{X-\mu}{\sqrt{\sigma^2}} \sim \normal(0,1)$ ($\nearrow$ HA 9.1) und nach \propref{8_10} folgt
	\begin{align*}
		\varphi_X(u) = \varphi_{\sigma Z + \mu} (u) = e^{\ii \mu u}\varphi_Z (\sigma u) = e^{\ii \mu  u}e^{-\frac{\sigma^2 u^2}{2}}.
	\end{align*}
\end{proof}
Die Charakteristische Funktion charakterisiert eine Verteilung eindeutig:
\begin{proposition}
	\proplbl{8_12} 
	Seien $(\O,\F,\P), (\O',\F',\P')$ Wahrscheinlichkeitsräume und $X: \O \to \Rd, Y: \O' \to \Rd$ Zufallsvariablen mit charakteristischen Funktionen $\varphi_X, \varphi_Y$. Dann:
	\begin{align*}
		X \distri Y \Longleftrightarrow \varphi_X(u) = \varphi_Y(u) \quad \forall u \in \Rd
	\end{align*}
\end{proposition}
Für den Beweis benötigen wir:
\begin{lemma}
	\proplbl{8_13} Seien $(\O,\F,\P),(\O', \F',\P')$ Wahrscheinlichkeitsräume, $X: \O \to \Rd$, $Y: \O' \to \Rd$ Zufallsvariablen. Dann gilt $X \distri Y$ genau dann, wenn
	\begin{align*}
		\E[f(X)] = \E'[f(Y)] \quad \forall f \in C_c (\Rd)
	\end{align*} 
	(Wobei $\E'[f(Y)]$ Erwartungswert bzgl $\P'$ und $C_c$ die Menge der stetigen Funktionen mit kompakten Träger sind)
\end{lemma}
\begin{proof}[\propref{8_13}]
	\begin{enumerate}
		\item $\implies$: klar.
		\item $\Longleftarrow$: Es genügt zu zeigen
		\begin{align*}
			\E[\indi_K(X)] = \P(X \in K) = \P'(Y \in K) = \E'[\indi_K(Y)] \label{bew:8_10}\tag{$\ast$}
		\end{align*}
		für alle $K \subset \Rd$ kompakt, denn die kompakten Mengen sind ein $\cap$-stabiler Erzeuger von $\borel(\Rd)$ und es gibt eine aufsteigende Folge $K_n \uparrow \Rd$. Die Indikatoren $\indi_K$ können wir durch $C_c$-Funktionen approximieren. Sei
		\begin{align*}
			\dist(x,A) &:= \inf_{y \in A}\abs{x-y} \quad A \subset \Rd\\
			f_n(x) &:= \frac{x, U_n^c}{\dist(x,U_n^c)+ \dist(x,K)} \quad U_n = \set{y \in \Rd\colon \dist(y,k) < \frac{1}{n}}
		\end{align*}
		Dann ist $f_n \in C_c$ mit $f_n \downarrow \indi_K$. Mit monotoner Konvergenz folgt \eqref{bew:8_10} aus der Vorraussetzung.
	\end{enumerate}
\end{proof}
\begin{proof}[\propref{8_12}]\leavevmode
	\begin{itemize}[topsep=-6pt,labelindent=0pt]
		\item[($\Rightarrow$)] klar
		\item[($\Leftarrow$)] Sei $\varphi_X(u) = \varphi_Y(u)$, $u \in \Rd$. Wir konstruieren $d$ unabhängige, identisch verteilte (u.i.v) Zufallsvariablen $N_1,\dots, N_d \sim \normal(0,1)$ unabhängig von $X$. Dann ist auch $N:=(N_1, \dots, N_d)$ unabhängig von $X$ ($\nearrow$~\cref{3_2_19}). Zudem gilt
		\begin{align*}
			\P(\sqrt{\sigma^2}N \in \d y) &= \prod_{i=1}^d \frac{1}{\sqrt{2\pi \sigma^2}} e^{-\frac{y_i^2}{2\sigma^2}} \d y_i\\
			&= (2\pi \sigma^2)^{-\frac{d}{2}} e^{-\frac{\abs{y}^2}{2\sigma^2}}\d y \quad\mit \abs{y} = \sqrt{\sum y_i^2}.
		\end{align*}
		Es gilt für alle $f \in C_c(\Rd)$:
		\begin{align*}
			\E[f(X + \sqrt{\sigma^2}N)] \overset{X \upmodels N}&{=} \int_{\Rd} \E[f(X +y)](2\pi\sigma^2)^{-\frac{d}{2}} e^{- \frac{\abs{y}^2}{2\sigma^2}} \d y\\
			&= (2 \pi \sigma^2)^{-\frac{d}{2}} \int_{\Rd} f(z) \E[e^{-\frac{\abs{X-z}^2}{2\sigma^2}}]\d z,
		\end{align*}
		wobei für $X \in \Rd$
		\begin{align*}
			e^{-\frac{\abs{X-z}^2}{2\sigma^2}}&= \prod_{i=1}^d \underbrace{e^{-\frac{\abs{X_i - z_i}^2}{\sigma^2}}}_{\varphi_{\normal(0,\sigma^2)}(X_i-z_i)}\\
			&= \prod_{i=1}^d \int_{\R} e^{\ii (X_i - z_i)y_i}\frac{\sigma}{\sqrt{2\pi}} e^{-\frac{\sigma^2y_i^2}{2}} \d y_i\\
			&= \frac{\sigma^d}{(2\pi)^{\frac{d}{2}}} \int_{\Rd} e^{\ii \scaProd{X-z}{y}}e^{-\frac{\sigma^2 \abs{y}^2}{2}} \d y,\\
			\intertext{so dass}
			\E[f(X+\sqrt{\sigma^2}N)] &= (2\pi)^{-d} \int_{\Rd} f(z) \E[\int_{\R} e^{\ii \scaProd{X-z}{y}}e^{-\frac{\sigma^2\abs{y}^2}{2}}\d y]\d z\\
			&= (2\pi)^{-d} \int_{\Rd} f(z) \int_{\Rd} \underbrace{\E[e^{\ii \scaProd{X}{Y}}]}_{\varphi_X(y)} e^{-\ii \scaProd{z}{y}}e^{-\frac{\sigma^2\abs{y}^2}{2}} \d y \d z \quad \text{ dom. Konv.}
		\end{align*}
		Dieselbe Rechnung auf $(\O', \F',\P')$ mit einem weiteren Vektor $N'$ u.i.v $\normal(0,1)$ Zufallsvariablen zeigt dann wegen $\varphi_X(u) = \varphi_Y(u)$.
		\begin{align*}
			\E[f(X + \sqrt{\sigma^2}N)] = \E'[f(Y + \sqrt{\sigma^2}N')]
		\end{align*}
		Mit dominierter Konvergenz folgt für $\sigma^2 \to 0$
		\begin{align*}
			\E[f(X)] = \E[f(Y)] \quad \forall f \in C_c (\Rd)
		\end{align*}
		Mit \propref{8_13} folgt die Behauptung.
	\end{itemize}
\end{proof}
Folgende Proposition is analog zu \propref{8_5}.
\begin{proposition}
	\proplbl{8_14}
	$(\;\F,\P)$ Wahrscheinlichkeitsraum, $X: \O \to \Rd$ Zufallsvariable mit charakteristischer Funktion $\varphi_X$. Wenn $\E[\norm{X}^n] < \infty$ für ein $n \in \N$, dann existiert
	\begin{align*}
		\partial^{\alpha} = \frac{\partial^{\abs{\alpha}}}{\partial^{\alpha_1}u_1 \cdots \partial^{\alpha_d}} \varphi_X(u) \\
		\forall \alpha \in \N^d_0 \mit \abs{\alpha} = \sum_{i=1}^d \alpha_i \le n
		\intertext{Zudem ist $\partial^{\alpha}_u \varphi_X$ stetig und es gilt}
		\E[X^{\alpha}] = i^{\abs{-\alpha}}\partial^{\alpha}_u \varphi_X(0)
	\end{align*}
\end{proposition}
\begin{proof}
	Da $\norm{x^{\alpha}} \le \norm{x}^{\abs{\alpha}}$ für $x \in \Rd, \alpha \in \N^d_0$ folgt aus der Annahme $\E[\norm{X^{\alpha}}] < \infty$. Damit 
	\begin{align*}
		\partial^{\alpha}_u \varphi_X(u) &= \int_{\Rd}e^{\ii \scaProd{u}{x}} \P(X \in \d x)\\
		\over{(\star)}&{=} \partial^{\alpha}_u \int_{\Rd} \partial^{\alpha}_u e^{\ii \scaProd{u}{x}} \P(X \in \d x)\\
		&= \int_{\Rd} (\ii x)^{\alpha} e^{\ii \scaProd{u}{x}} \P(X \in \d x)\\
		&= \ii^{\abs{\alpha}}\int_{\Rd} e^{\ii \scaProd{u}{x}} \P(X \in \d x)\\
	\end{align*}
	so dass die Ableitung existiert und für $u = 0$ die Momentenformel folgt. In $(\star)$ haben wir $\abs{\alpha}$-mal das Differenzierbarkeitslemma ($\nearrow$ MINT Satz 12.1) verwendet, wobei $\partial^{\alpha}_u e^{\ii \scaProd{u}{x}}$ intbar ist, da
	\begin{align*}
		\norm{\partial^{\alpha}_u e^{\ii \scaProd{u}{x}}} = \norm{(\ii x)^{\alpha} e^{\ii \scaProd{u}{x}}} = \norm{(\ii x)^{\alpha}} = \norm{x^{\alpha}}.
	\end{align*}
\end{proof}